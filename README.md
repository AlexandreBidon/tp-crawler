# TP 1 : Construire un crawler minimal

## Présentation
**Auteur** : Alexandre Bidon

**Note** : Ce repo contient le code d'un TP du cours d'indexation web. Le sujet du TP est [disponible ici](https://github.com/AlexandreBidon/tp-crawler/blob/master/docs/TP1.pdf).

Ce repo présente une implémentation basique d'un crawler web. L'objectif est de récupérer un certain nombre d'url de pages en respectant les règles du crawling, à savoir :

- respecter la politeness : ne pas effectuer trop de requetes sur un meme site
- Ne pas crawler un site qui nous l'interdit : vérifier le robots.txt

#### Comment lancer le crawler

Pour commencer il faut installer les dépendances du projet :

> pip install -r requirements.txt

Le fichier main.py contient une démo du crawler. 

## Fonctionnement



## Limites
